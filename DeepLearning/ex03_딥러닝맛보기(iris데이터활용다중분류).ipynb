{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d83cbc8",
   "metadata": {},
   "source": [
    "### 목표\n",
    "- iris 데이터를 활용해서 붓꽃 품종을 분류해보자.\n",
    "- 신경망에서 다중 분류 학습을 진행해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39222b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee32648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "data \n",
    "# 딕셔너리 -> 접근 : 딕셔너리['키']\n",
    "# 번치객체 bunch 다발 묶음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76302d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키값들 확인하기\n",
    "data.keys()\n",
    "\n",
    "# target 답\n",
    "# data 문제 = 특성 = 속성 = 피처\n",
    "# target_names 답데이터 이름\n",
    "# feature_names 특성 이름\n",
    "# DESCR 묘사하다, 기술하다 : 데이터의 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c82e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 답데이터 살펴보기\n",
    "data.target\n",
    "\n",
    "# 분류 종류 3가지 - 0-'setosa', 1-'versicolor', 2-'virginica'\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5fa5fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제데이터 살펴보기\n",
    "data.data.shape\n",
    "\n",
    "# 피처 이름들 살펴보기\n",
    "data.feature_names\n",
    "\n",
    "# 'sepal length (cm)', 꽃받침의 길이\n",
    "# 'sepal width (cm)', 꽃받침의 너비\n",
    "# 'petal length (cm)', 꽃잎의 길이\n",
    "# 'petal width (cm)' 꽃잎의 너비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcff8ebc",
   "metadata": {},
   "source": [
    "#### 데이터 분리\n",
    "- 문제와 답으로 분리\n",
    "- 훈련용, 테스트용으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fcab6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련문제 (120, 4)\n",
      "훈련답 (30, 4)\n",
      "테스트문제 (120,)\n",
      "테스트답 (30,)\n"
     ]
    }
   ],
   "source": [
    "# 문제\n",
    "X = data.data\n",
    "# 답\n",
    "y = data.target\n",
    "# X_train, X_test, y_train, y_test\n",
    "# 8:2\n",
    "# 고정값 3\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state = 3)\n",
    "# 크기확인\n",
    "print('훈련문제', X_train.shape)\n",
    "print('훈련답', X_test.shape)\n",
    "print('테스트문제', y_train.shape)\n",
    "print('테스트답', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4627e8",
   "metadata": {},
   "source": [
    "#### 답데이터 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b235d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.get_dummies(대상) --> pandas\n",
    "# to_categorical(대상) --> tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# train\n",
    "y_tr_oh = to_categorical(y_train)\n",
    "# test\n",
    "y_te_oh = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0101602e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원핫인코딩 됐는지 확인\n",
    "y_tr_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78e4fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_oh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3508a",
   "metadata": {},
   "source": [
    "#### 인공신경망 생성하기!\n",
    "- 1. 신경망 구조 설계(뼈대, 층 정의)\n",
    "- 2. 학습/평가 방법 설정\n",
    "- 3. 학습 및 시각화\n",
    "- 4. 모델 평가 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8283b0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 987\n",
      "Trainable params: 987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# 1. 뼈대 생성\n",
    "model = Sequential()\n",
    "# 2. 입력 + 중간층 설정\n",
    "# 뉴런개수 16\n",
    "# relu\n",
    "model.add(Dense(units = 16, input_dim = 4, activation = 'relu'))\n",
    "# 중간층 2개\n",
    "# 뉴런개수 32\n",
    "# 뉴런개수 10\n",
    "# relu\n",
    "model.add(Dense(units = 32, activation = 'relu'))\n",
    "model.add(Dense(units = 10, activation = 'relu'))\n",
    "# 출력층\n",
    "# 다중분류 : 출력층의 뉴런의 개수는 몇개? 활성화함수 이름?\n",
    "# 다중분류 : 클래스 레이블의 개수만큼\n",
    "# 활성화함수 : softmax\n",
    "model.add(Dense(units = 3, activation = 'softmax'))\n",
    "# 요약\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d43ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습/평가방법 (모델 컴파일)\n",
    "# compile\n",
    "# 다중분류 loss : categorical_crossentropy\n",
    "model.compile(loss = 'categorical_crossentropy', # 에러 측정(실제와 예측 차이 측정)\n",
    "                     optimizer = 'adam', # 최적화 : 확률적 경사 하강법\n",
    "                     metrics = ['accuracy'] ) # 평가 지표 : 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84fa80fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 0s 505us/step - loss: 0.0597 - accuracy: 0.9917\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 497us/step - loss: 0.0608 - accuracy: 0.9917\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0584 - accuracy: 0.9917\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0618 - accuracy: 0.9917\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0568 - accuracy: 0.9917\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9917\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.0603 - accuracy: 0.9917\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0572 - accuracy: 0.9917\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0598 - accuracy: 0.9917\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9917\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0585 - accuracy: 0.9917\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0592 - accuracy: 0.9917\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.0575 - accuracy: 0.9917\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0563 - accuracy: 0.9917\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0584 - accuracy: 0.9917\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0587 - accuracy: 0.9917\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0574 - accuracy: 0.9917\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 504us/step - loss: 0.0575 - accuracy: 0.9917\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0577 - accuracy: 0.9917\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.0580 - accuracy: 0.9917\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0577 - accuracy: 0.9917\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0556 - accuracy: 0.9917\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0610 - accuracy: 0.9917\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0552 - accuracy: 0.9917\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0575 - accuracy: 0.9917\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0589 - accuracy: 0.9917\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 742us/step - loss: 0.0556 - accuracy: 0.9917\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0570 - accuracy: 0.9917\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0581 - accuracy: 0.9917\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0571 - accuracy: 0.9917\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0560 - accuracy: 0.9917\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0621 - accuracy: 0.9833\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.0548 - accuracy: 0.9917\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0571 - accuracy: 0.9917\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0622 - accuracy: 0.9833\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0614 - accuracy: 0.9917\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9917\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0605 - accuracy: 0.9917\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 744us/step - loss: 0.0577 - accuracy: 0.9917\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0568 - accuracy: 0.9917\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0576 - accuracy: 0.9917\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0556 - accuracy: 0.9917\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0565 - accuracy: 0.9917\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.0590 - accuracy: 0.9917\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0558 - accuracy: 0.9917\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0543 - accuracy: 0.9917\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.0564 - accuracy: 0.9917\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.0551 - accuracy: 0.9917\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0558 - accuracy: 0.9917\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0544 - accuracy: 0.9917\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0548 - accuracy: 0.9917\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0545 - accuracy: 0.9917\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0557 - accuracy: 0.9917\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.0544 - accuracy: 0.9917\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0560 - accuracy: 0.9917\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0557 - accuracy: 0.9917\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0549 - accuracy: 0.9917\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0569 - accuracy: 0.9917\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0553 - accuracy: 0.9917\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0551 - accuracy: 0.9917\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0537 - accuracy: 0.9917\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0537 - accuracy: 0.9917\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0542 - accuracy: 0.9917\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0538 - accuracy: 0.9917\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.0536 - accuracy: 0.9917\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0540 - accuracy: 0.9917\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0563 - accuracy: 0.9917\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 502us/step - loss: 0.0548 - accuracy: 0.9917\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0535 - accuracy: 0.9917\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0539 - accuracy: 0.9917\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0550 - accuracy: 0.9917\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0539 - accuracy: 0.9917\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0556 - accuracy: 0.9917\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0531 - accuracy: 0.9917\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0532 - accuracy: 0.9917\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0524 - accuracy: 0.9917\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0546 - accuracy: 0.9917\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0530 - accuracy: 0.9917\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.0527 - accuracy: 0.9917\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0527 - accuracy: 0.9917\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9917\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0529 - accuracy: 0.9917\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9917\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0561 - accuracy: 0.9917\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0537 - accuracy: 0.9917\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0530 - accuracy: 0.9917\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0526 - accuracy: 0.9917\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0522 - accuracy: 0.9917\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0533 - accuracy: 0.9917\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 743us/step - loss: 0.0527 - accuracy: 0.9917\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0523 - accuracy: 0.9917\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.0526 - accuracy: 0.9917\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0520 - accuracy: 0.9917\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0550 - accuracy: 0.9917\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0523 - accuracy: 0.9917\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0524 - accuracy: 0.9917\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0526 - accuracy: 0.9917\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 0.9917\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0534 - accuracy: 0.9917\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.0561 - accuracy: 0.9917\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0519 - accuracy: 0.9917\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0519 - accuracy: 0.9917\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0530 - accuracy: 0.9917\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 996us/step - loss: 0.0522 - accuracy: 0.9917\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.0512 - accuracy: 0.9917\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0518 - accuracy: 0.9917\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0515 - accuracy: 0.9917\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0524 - accuracy: 0.9917\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0519 - accuracy: 0.9917\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0522 - accuracy: 0.9917\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0532 - accuracy: 0.9917\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0523 - accuracy: 0.9917\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 745us/step - loss: 0.0523 - accuracy: 0.9917\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0543 - accuracy: 0.9917\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0540 - accuracy: 0.9917\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0542 - accuracy: 0.9917\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0506 - accuracy: 0.9917\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0513 - accuracy: 0.9917\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0528 - accuracy: 0.9917\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 515us/step - loss: 0.0540 - accuracy: 0.9917\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0507 - accuracy: 0.9917\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 741us/step - loss: 0.0515 - accuracy: 0.9917\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 494us/step - loss: 0.0515 - accuracy: 0.9917\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 490us/step - loss: 0.0533 - accuracy: 0.9917\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0540 - accuracy: 0.9917\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0519 - accuracy: 0.9917\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 487us/step - loss: 0.0505 - accuracy: 0.9917\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.0510 - accuracy: 0.9917\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 740us/step - loss: 0.0528 - accuracy: 0.9917\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 492us/step - loss: 0.0514 - accuracy: 0.9917\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 492us/step - loss: 0.0510 - accuracy: 0.9917\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0521 - accuracy: 0.9917\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0524 - accuracy: 0.9917\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0513 - accuracy: 0.9917\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0526 - accuracy: 0.9917\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 505us/step - loss: 0.0507 - accuracy: 0.9917\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.0515 - accuracy: 0.9917\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 491us/step - loss: 0.0510 - accuracy: 0.9917\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 491us/step - loss: 0.0512 - accuracy: 0.9917\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 490us/step - loss: 0.0520 - accuracy: 0.9917\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 486us/step - loss: 0.0546 - accuracy: 0.9917\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 502us/step - loss: 0.0556 - accuracy: 0.9917\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0510 - accuracy: 0.9917\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0511 - accuracy: 0.9917\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 741us/step - loss: 0.0497 - accuracy: 0.9917\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 490us/step - loss: 0.0502 - accuracy: 0.9917\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 868us/step - loss: 0.0495 - accuracy: 0.9917\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0515 - accuracy: 0.9917\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0501 - accuracy: 0.9917\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0517 - accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "# 3-1. 학습 fit\n",
    "h = model.fit(X_train, y_tr_oh, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cecbd42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3-2. 선그래프 시각화\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(range(1,151), h.history['accuracy'], label='acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59ef0204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 평가 및 예측\n",
    "pre = model.predict(X_test)\n",
    "# 각각의 클래스에 대한 확률정보가 출력됨\n",
    "pre[0].argmax() # 제일 큰값이 있는 인덱스 번호 출력 함수\n",
    "# setosa품종으로 예측했음을 알 수 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
