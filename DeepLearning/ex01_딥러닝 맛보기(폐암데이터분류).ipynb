{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc58c907",
   "metadata": {},
   "source": [
    "### 목표\n",
    "- 폐암환자의 생존을 예측하는 분류 모델을 만들어보자\n",
    "- 다층퍼셉트론(인공신경망)을 활용하여 이진분류 문제를 해결해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42d7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914c9dd",
   "metadata": {},
   "source": [
    "#### 데이터 불러오기\n",
    "- pd.read_csv(경로, header =)\n",
    "- header : 데이터를 불러오면서 컬럼명을 설정해주는 키워드\n",
    "  (None : 인덱스번호로 컬럼명 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e2b801f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>369</td>\n",
       "      <td>6</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>406</td>\n",
       "      <td>6</td>\n",
       "      <td>5.36</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>447</td>\n",
       "      <td>8</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1     2     3   4   5   6   7   8   9   10  11  12  13  14  15  16  \\\n",
       "0    293   1  3.80  2.80   0   0   0   0   0   0  12   0   0   0   1   0  62   \n",
       "1      1   2  2.88  2.16   1   0   0   0   1   1  14   0   0   0   1   0  60   \n",
       "2      8   2  3.19  2.50   1   0   0   0   1   0  11   0   0   1   1   0  66   \n",
       "3     14   2  3.98  3.06   2   0   0   0   1   1  14   0   0   0   1   0  80   \n",
       "4     17   2  2.21  1.88   0   0   1   0   0   0  12   0   0   0   1   0  56   \n",
       "..   ...  ..   ...   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "465   98   6  3.04  2.40   2   0   0   0   1   0  11   0   0   0   1   0  76   \n",
       "466  369   6  3.88  2.72   1   0   0   0   1   0  12   0   0   0   1   0  77   \n",
       "467  406   6  5.36  3.96   1   0   0   0   1   0  12   0   0   0   0   0  62   \n",
       "468   25   8  4.32  3.20   0   0   0   0   0   0  11   0   0   0   0   0  58   \n",
       "469  447   8  5.20  4.10   0   0   0   0   0   0  12   0   0   0   0   0  49   \n",
       "\n",
       "     17  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  \n",
       "3     1  \n",
       "4     0  \n",
       "..   ..  \n",
       "465   0  \n",
       "466   0  \n",
       "467   0  \n",
       "468   1  \n",
       "469   0  \n",
       "\n",
       "[470 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 내부 의미보다는 문제, 답 구분에 집중\n",
    "# 인공신경망 구축해서 학습시키기\n",
    "data = pd.read_csv('./data/ThoraricSurgery.csv', header = None)\n",
    "data\n",
    "\n",
    "# 답 데이터 : 17번째 컬럼\n",
    "# 0-사망, 1-생존\n",
    "# 특성 데이터 : 17번째 제외한 나머지 컬럼들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef1d30",
   "metadata": {},
   "source": [
    "- 데이터 크기 확인\n",
    "- 데이터 결측치 여부 확인\n",
    "- 데이터 타입 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d021dee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 470 entries, 0 to 469\n",
      "Data columns (total 18 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       470 non-null    int64  \n",
      " 1   1       470 non-null    int64  \n",
      " 2   2       470 non-null    float64\n",
      " 3   3       470 non-null    float64\n",
      " 4   4       470 non-null    int64  \n",
      " 5   5       470 non-null    int64  \n",
      " 6   6       470 non-null    int64  \n",
      " 7   7       470 non-null    int64  \n",
      " 8   8       470 non-null    int64  \n",
      " 9   9       470 non-null    int64  \n",
      " 10  10      470 non-null    int64  \n",
      " 11  11      470 non-null    int64  \n",
      " 12  12      470 non-null    int64  \n",
      " 13  13      470 non-null    int64  \n",
      " 14  14      470 non-null    int64  \n",
      " 15  15      470 non-null    int64  \n",
      " 16  16      470 non-null    int64  \n",
      " 17  17      470 non-null    int64  \n",
      "dtypes: float64(2), int64(16)\n",
      "memory usage: 66.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "#행 470\n",
    "#열 18 (특성 17개, 답 1개)\n",
    "#결측치x\n",
    "#모든 데이터는 수치값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ecf20b",
   "metadata": {},
   "source": [
    "#### 문제와 답으로 분리\n",
    "- 문제 : X\n",
    "- 답 : y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca82090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제 크기 :  (470, 17)\n",
      "답 크기 :  (470,)\n"
     ]
    }
   ],
   "source": [
    "X = data.loc[:, :16]\n",
    "y = data[17]\n",
    "print('문제 크기 : ', X.shape)\n",
    "print('답 크기 : ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15a251",
   "metadata": {},
   "source": [
    "#### 훈련셋과 테스트셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9af26f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 문제: (329, 17)\n",
      "훈련용 답: (329,)\n",
      "테스트 문제: (141, 17)\n",
      "테스트 답: (141,)\n"
     ]
    }
   ],
   "source": [
    "# 도구 임포트\n",
    "# 7:3 분리\n",
    "# 랜덤고정 : 5\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state = 5)\n",
    "# 크기확인하기\n",
    "print(\"훈련용 문제:\", X_train.shape)\n",
    "print(\"훈련용 답:\", y_train.shape)\n",
    "print(\"테스트 문제:\", X_test.shape)\n",
    "print(\"테스트 답:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1d161",
   "metadata": {},
   "source": [
    "#### keras를 활용하여 모델 구축하기\n",
    "1. 신경망 구조 설계(뼈대 생성, 층 설계)\n",
    "2. 학습/평가하는 방법 설정\n",
    "3. 학습 + 학습현황 시각화\n",
    "4. 모델 평가 / 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26be6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개\n",
    "# Activation()-> Dense() 함수 안에 있는 activation 사용\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c60d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                180       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 279\n",
      "Trainable params: 279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. 신경망 구조 설계(뼈대 생성)\n",
    "# 이진분류 하는 모델\n",
    "model_binary = Sequential()\n",
    "\n",
    "# 뼈대생성 후 층 설계\n",
    "# 입력층 + 중간층\n",
    "# 모델이 학습할 특성의 개수 : 17\n",
    "model_binary.add(Dense(units = 10, input_dim = 17, activation = 'sigmoid'))\n",
    "\n",
    "# 중간층 2개 쌓아보기\n",
    "# 뉴런 6으로 설정해서 쌓아보기\n",
    "model_binary.add(Dense(units = 6, activation = 'sigmoid')) #퍼셉트론 층\n",
    "# 뉴런 4로 설정해서 쌓아보기\n",
    "model_binary.add(Dense(units = 4, activation = 'sigmoid')) #퍼셉트론 층\n",
    "\n",
    "# 출력층 설정\n",
    "# 회귀 : 출력층 활성화 함수를 ax+b 그대로 사용\n",
    "# 분류 : 출력층 활성화 함수 연결\n",
    "# 이진분류, 다중분류에 따라서 달라질 수 있음\n",
    "# 이진분류 - 'sigmoid' 꼭 붙어야함!\n",
    "# 뉴런 1, 활성화함수\n",
    "model_binary.add(Dense(units=1, activation = 'sigmoid'))\n",
    "\n",
    "# 모델 정보 요약\n",
    "model_binary.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07213fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 : 출력층 뉴런 개수 1, 활성화함수 : ax+b(선형함수)- 따로 설정해줄 필요X\n",
    "# 분류 : 이진분류 출력층 뉴런 개수 1, 활성화함수 설정 O - sigmoid\n",
    "        #다중분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "587b4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습 / 평가 설정\n",
    "# compile\n",
    "model_binary.compile(loss = 'binary_crossentropy', # 에러 측정(실제와 예측 차이 측정)\n",
    "                     optimizer = 'sgd', # 최적화 : 확률적 경사 하강법\n",
    "                     metrics = ['accuracy'] ) # 평가 지표 : 정확도\n",
    "# from sklearn.metrics import accuracy_score # 정확도 측정\n",
    "# 정확도 : 0은 0이고, 1은 1이라고 얼마나 맞췄는지를 측정\n",
    "# tree_model.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc11463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 541us/step - loss: 0.7583 - accuracy: 0.1459\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.7160 - accuracy: 0.1459\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 540us/step - loss: 0.6806 - accuracy: 0.7538\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 542us/step - loss: 0.6487 - accuracy: 0.8541\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.6211 - accuracy: 0.8541\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 499us/step - loss: 0.5983 - accuracy: 0.8541\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.5778 - accuracy: 0.8541\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.5600 - accuracy: 0.8541\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5444 - accuracy: 0.8541\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5306 - accuracy: 0.8541\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5185 - accuracy: 0.8541\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 513us/step - loss: 0.5083 - accuracy: 0.8541\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.4991 - accuracy: 0.8541\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 488us/step - loss: 0.4907 - accuracy: 0.8541\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4835 - accuracy: 0.8541\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 494us/step - loss: 0.4773 - accuracy: 0.8541\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 451us/step - loss: 0.4712 - accuracy: 0.8541\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 456us/step - loss: 0.4654 - accuracy: 0.8541\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4610 - accuracy: 0.8541\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4565 - accuracy: 0.8541\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 446us/step - loss: 0.4529 - accuracy: 0.8541\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 409us/step - loss: 0.4500 - accuracy: 0.8541\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 542us/step - loss: 0.4469 - accuracy: 0.8541\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4440 - accuracy: 0.8541\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4415 - accuracy: 0.8541\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 722us/step - loss: 0.4391 - accuracy: 0.8541\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.4374 - accuracy: 0.8541\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 553us/step - loss: 0.4358 - accuracy: 0.8541\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 451us/step - loss: 0.4339 - accuracy: 0.8541\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4325 - accuracy: 0.8541\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4313 - accuracy: 0.8541\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4300 - accuracy: 0.8541\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4289 - accuracy: 0.8541\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4277 - accuracy: 0.8541\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 488us/step - loss: 0.4267 - accuracy: 0.8541\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4259 - accuracy: 0.8541\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 545us/step - loss: 0.4250 - accuracy: 0.8541\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4243 - accuracy: 0.8541\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4237 - accuracy: 0.8541\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 423us/step - loss: 0.4232 - accuracy: 0.8541\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4228 - accuracy: 0.8541\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 547us/step - loss: 0.4222 - accuracy: 0.8541\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 451us/step - loss: 0.4216 - accuracy: 0.8541\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 399us/step - loss: 0.4211 - accuracy: 0.8541\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 451us/step - loss: 0.4208 - accuracy: 0.8541\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 360us/step - loss: 0.4204 - accuracy: 0.8541\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 451us/step - loss: 0.4200 - accuracy: 0.8541\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 451us/step - loss: 0.4197 - accuracy: 0.8541\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 451us/step - loss: 0.4195 - accuracy: 0.8541\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4193 - accuracy: 0.8541\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 450us/step - loss: 0.4191 - accuracy: 0.8541\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4189 - accuracy: 0.8541\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 452us/step - loss: 0.4185 - accuracy: 0.8541\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 366us/step - loss: 0.4183 - accuracy: 0.8541\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4181 - accuracy: 0.8541\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 365us/step - loss: 0.4179 - accuracy: 0.8541\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4176 - accuracy: 0.8541\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.4175 - accuracy: 0.8541\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 545us/step - loss: 0.4174 - accuracy: 0.8541\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 456us/step - loss: 0.4173 - accuracy: 0.8541\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 542us/step - loss: 0.4172 - accuracy: 0.8541\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.4172 - accuracy: 0.8541\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.4171 - accuracy: 0.8541\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 638us/step - loss: 0.4170 - accuracy: 0.8541\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4169 - accuracy: 0.8541\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 451us/step - loss: 0.4167 - accuracy: 0.8541\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4167 - accuracy: 0.8541\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4166 - accuracy: 0.8541\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4165 - accuracy: 0.8541\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.4164 - accuracy: 0.8541\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 637us/step - loss: 0.4163 - accuracy: 0.8541\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 542us/step - loss: 0.4163 - accuracy: 0.8541\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 592us/step - loss: 0.4162 - accuracy: 0.8541\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 515us/step - loss: 0.4162 - accuracy: 0.8541\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 462us/step - loss: 0.4162 - accuracy: 0.8541\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4162 - accuracy: 0.8541\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4160 - accuracy: 0.8541\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 451us/step - loss: 0.4160 - accuracy: 0.8541\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 995us/step - loss: 0.4160 - accuracy: 0.8541\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4159 - accuracy: 0.8541\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 544us/step - loss: 0.4159 - accuracy: 0.8541\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 817us/step - loss: 0.4159 - accuracy: 0.8541\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 491us/step - loss: 0.4159 - accuracy: 0.8541\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8541\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 736us/step - loss: 0.4159 - accuracy: 0.8541\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 632us/step - loss: 0.4158 - accuracy: 0.8541\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 818us/step - loss: 0.4158 - accuracy: 0.8541\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 719us/step - loss: 0.4159 - accuracy: 0.8541\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 542us/step - loss: 0.4158 - accuracy: 0.8541\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 724us/step - loss: 0.4158 - accuracy: 0.8541\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 543us/step - loss: 0.4158 - accuracy: 0.8541\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4157 - accuracy: 0.8541\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 545us/step - loss: 0.4157 - accuracy: 0.8541\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 601us/step - loss: 0.4157 - accuracy: 0.8541\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 452us/step - loss: 0.4157 - accuracy: 0.8541\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 543us/step - loss: 0.4157 - accuracy: 0.8541\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.4157 - accuracy: 0.8541\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 525us/step - loss: 0.4157 - accuracy: 0.8541\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 547us/step - loss: 0.4157 - accuracy: 0.8541\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 542us/step - loss: 0.4157 - accuracy: 0.8541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26fc840de48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 모델 학습\n",
    "# fit\n",
    "# 반복횟수 = 100\n",
    "\n",
    "h = model_binary.fit(X_train, y_train, epochs=100)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f29e8090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습현황 시각화\n",
    "# accuracy값을 기준으로 시각화\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(range(1,101), h.history['accuracy'], label='acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# 초반의 w, b를 잘 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec331efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5433 - accuracy: 0.7812WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.4335 - accuracy: 0.8440\n",
      "loss: 0.4335494935512543\n",
      "acc: 0.8439716100692749\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 평가\n",
    "result = model_binary.evaluate(X_test,y_test)\n",
    "# 84% 성능 - 성능 나름 괜찮음\n",
    "print('loss:',result[0])\n",
    "print('acc:', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c94f710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14858311],\n",
       "       [0.1563248 ],\n",
       "       [0.14858457],\n",
       "       [0.14858556],\n",
       "       [0.14858311],\n",
       "       [0.14858326],\n",
       "       [0.14858776],\n",
       "       [0.15632486],\n",
       "       [0.14858505],\n",
       "       [0.14858225],\n",
       "       [0.14858168],\n",
       "       [0.14877567],\n",
       "       [0.14858457],\n",
       "       [0.14858255],\n",
       "       [0.1485787 ],\n",
       "       [0.1485982 ],\n",
       "       [0.14858326],\n",
       "       [0.14858028],\n",
       "       [0.14858177],\n",
       "       [0.14858076],\n",
       "       [0.1485888 ],\n",
       "       [0.14858648],\n",
       "       [0.14878294],\n",
       "       [0.14858276],\n",
       "       [0.1485835 ],\n",
       "       [0.14860523],\n",
       "       [0.14903826],\n",
       "       [0.14858398],\n",
       "       [0.14858851],\n",
       "       [0.14858568],\n",
       "       [0.14858586],\n",
       "       [0.14945361],\n",
       "       [0.14857942],\n",
       "       [0.14858264],\n",
       "       [0.15004188],\n",
       "       [0.14858499],\n",
       "       [0.14858842],\n",
       "       [0.14858273],\n",
       "       [0.14858711],\n",
       "       [0.14859116],\n",
       "       [0.148588  ],\n",
       "       [0.15509799],\n",
       "       [0.1486103 ],\n",
       "       [0.14858168],\n",
       "       [0.14896488],\n",
       "       [0.14858297],\n",
       "       [0.14858457],\n",
       "       [0.14858484],\n",
       "       [0.14857984],\n",
       "       [0.1486299 ],\n",
       "       [0.14858893],\n",
       "       [0.14858288],\n",
       "       [0.14858758],\n",
       "       [0.14861554],\n",
       "       [0.14858055],\n",
       "       [0.14858285],\n",
       "       [0.14858335],\n",
       "       [0.14858323],\n",
       "       [0.14858437],\n",
       "       [0.14858362],\n",
       "       [0.1486446 ],\n",
       "       [0.1485807 ],\n",
       "       [0.14858326],\n",
       "       [0.14890584],\n",
       "       [0.14858213],\n",
       "       [0.14858311],\n",
       "       [0.14858785],\n",
       "       [0.1485661 ],\n",
       "       [0.14858264],\n",
       "       [0.14858675],\n",
       "       [0.14858434],\n",
       "       [0.14858404],\n",
       "       [0.1485846 ],\n",
       "       [0.14858294],\n",
       "       [0.1485838 ],\n",
       "       [0.14859325],\n",
       "       [0.14858276],\n",
       "       [0.14858556],\n",
       "       [0.14860332],\n",
       "       [0.14858633],\n",
       "       [0.14860672],\n",
       "       [0.1485838 ],\n",
       "       [0.14858225],\n",
       "       [0.14862311],\n",
       "       [0.14851934],\n",
       "       [0.14941117],\n",
       "       [0.1485821 ],\n",
       "       [0.14858264],\n",
       "       [0.14858297],\n",
       "       [0.14858434],\n",
       "       [0.14858457],\n",
       "       [0.14879   ],\n",
       "       [0.14858717],\n",
       "       [0.14858264],\n",
       "       [0.1485832 ],\n",
       "       [0.14858404],\n",
       "       [0.14858738],\n",
       "       [0.14859214],\n",
       "       [0.14858449],\n",
       "       [0.14857462],\n",
       "       [0.14858285],\n",
       "       [0.1485829 ],\n",
       "       [0.1493482 ],\n",
       "       [0.14858478],\n",
       "       [0.14858398],\n",
       "       [0.15611771],\n",
       "       [0.14858413],\n",
       "       [0.14858288],\n",
       "       [0.14858764],\n",
       "       [0.14860126],\n",
       "       [0.14859432],\n",
       "       [0.14858404],\n",
       "       [0.14858404],\n",
       "       [0.14858988],\n",
       "       [0.1485849 ],\n",
       "       [0.14856744],\n",
       "       [0.14858311],\n",
       "       [0.14858115],\n",
       "       [0.14858478],\n",
       "       [0.14865649],\n",
       "       [0.1485829 ],\n",
       "       [0.148523  ],\n",
       "       [0.14859426],\n",
       "       [0.14860779],\n",
       "       [0.14867824],\n",
       "       [0.14860854],\n",
       "       [0.14858237],\n",
       "       [0.14858311],\n",
       "       [0.1485965 ],\n",
       "       [0.14858356],\n",
       "       [0.14855081],\n",
       "       [0.1485841 ],\n",
       "       [0.15687796],\n",
       "       [0.14858481],\n",
       "       [0.14884344],\n",
       "       [0.14860177],\n",
       "       [0.148586  ],\n",
       "       [0.14861187],\n",
       "       [0.14859322],\n",
       "       [0.14858362],\n",
       "       [0.14858162]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "# predict\n",
    "model_binary.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b336c83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\smhrd\\AppData\\Local\\Temp\\ipykernel_5368\\66996882.py:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_binary.predict_classes(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
