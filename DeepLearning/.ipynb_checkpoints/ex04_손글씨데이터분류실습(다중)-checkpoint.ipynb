{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e6ce13",
   "metadata": {},
   "source": [
    "### 목표\n",
    "- 신경망을 활용해서 다중분류에 필요한 keras 기능을 이해해보자\n",
    "- 이미지데이터를 신경망에 입력하기 위해 필요한 전처리를 이해해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419a7c57",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0863f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# 문제와 답, 훈련과 테스트 모두 분리가 되어 있음\n",
    "# mnist상에서 3차원 형식으로 묶어짐\n",
    "# [[[X_train],[y_train]],[[X_test],[y_test]]]\n",
    "(X_train, y_train), (X_test, y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca588b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용문제: (60000, 28, 28)\n",
      "훈련용답: (60000,)\n",
      "테스트용문제: (10000, 28, 28)\n",
      "테스트용답: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 크기확인\n",
    "# shape\n",
    "# digit_train\n",
    "print('훈련용문제:', X_train.shape)\n",
    "print('훈련용답:', y_train.shape)\n",
    "print('테스트용문제:', X_test.shape)\n",
    "print('테스트용답:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2efb74e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3ec66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0~9 : 10개\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8093dbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# 이미지 살펴보기\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 첫번째 이미지 그림 출력해보기\n",
    "digit = X_train[0]\n",
    "label = y_train[0]\n",
    "\n",
    "#display(digit) # display 출력하는 함수(자료형식 그대로 출력)\n",
    "#display(label)\n",
    "\n",
    "# 데이터타입\n",
    "# unit8 : 양의 정수 의미하는 자료형\n",
    "plt.imshow(digit,cmap = 'gray')\n",
    "plt.show()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218e9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 특성\n",
    "# 가로 size : 28, 세로size : 28\n",
    "# 배경은 검정색(0), 글씨는 흰색(255)으로 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31b644",
   "metadata": {},
   "source": [
    "이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3c1b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 이미지 크기 변경\n",
    "# 1. 인공 신경망 입력값은 1차원이어야함, 우리 이미지는 2차원\n",
    "#    2->1차원으로 변환\n",
    "# 2. 픽셀값의 범위가 0~255분산이 큰 상태\n",
    "#    픽셀값 단위를 0,0~1,0의 범위로 변환해서 분산을 줄임 -> 정확도 향상\n",
    "\n",
    "# (1)\n",
    "X_train = X_train.reshape(60000, 28*28)\n",
    "X_test = X_test.reshape(10000, 28*28)\n",
    "\n",
    "# (2)\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "# 크기 확인\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33996b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b982802e",
   "metadata": {},
   "source": [
    "답데이터 전처리\n",
    "- 0~9:10개\n",
    "- 원핫인코딩\n",
    "- get_dummies(대상), to_categorial(대상)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba44491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "#pd.get_dummies\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# y_train\n",
    "y_tr_en = to_categorical(y_train)\n",
    "# y_test\n",
    "y_te_en = to_categorical(y_test)\n",
    "\n",
    "print(y_tr_en.shape)\n",
    "print(y_te_en.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430834f2",
   "metadata": {},
   "source": [
    "신경망 설계\n",
    "- 1. 신경망 구축(뼈대, 층 정의)\n",
    "- 2. 학습/평가 방법 설정\n",
    "- 3. 학습 및 시각화\n",
    "- 4. 평가 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1736e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79b19a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 600)               471000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                15050     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 666,860\n",
      "Trainable params: 666,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. 신경망 구축\n",
    "model = Sequential()\n",
    "\n",
    "#입력+중간층\n",
    "# add() : 신경망 층을 추가\n",
    "# Dense() : 층을 정의(유닛의 수, 입력수, 활성화함수)\n",
    "# input_dim : 특성(열)의 개수만큼\n",
    "# activation : 활성화 함수\n",
    "model.add(Dense(units = 600, input_dim = 784, activation = 'relu'))\n",
    "#중간층(은닉층) : 특성을 추출하고 선택(데이터 전처리)\n",
    "# -내부 값들은 파악하기 어려움\n",
    "# XAI : 설명가능한 인공지능 연구가 계속됨\n",
    "model.add(Dense(300, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "#출력층 : 결과를 출력\n",
    "# units : y의 개수만큼(클래스 레이블의 크기)\n",
    "model.add(Dense(units = 10, activation = 'softmax'))\n",
    "# 요약\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층 설정\n",
    "# - 회귀분석\n",
    "# - units = 1, activation = 'linear'(항등함수) 또는 생략가능(기본)\n",
    "# - 이진분류\n",
    "# - 답데이터 원핫인코딩 안해도 됨\n",
    "# - units=1, activation = 'sigmoid'\n",
    "# - 답데이터에 원핫인코딩을 했을 경우\n",
    "# - units=2, activation = 'softmax'\n",
    "# - 다중분류\n",
    "# - 답데이터 원핫인코딩 해야함\n",
    "# - units=클래스의 개수, activation='softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "201ddf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습/평가 방법 설정\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "255fc0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2732 - accuracy: 0.9212\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0964 - accuracy: 0.9708\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0622 - accuracy: 0.9808\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0427 - accuracy: 0.9864\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0296 - accuracy: 0.9907\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0240 - accuracy: 0.9924\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0166 - accuracy: 0.9947\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0169 - accuracy: 0.9948\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0136 - accuracy: 0.9951\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0128 - accuracy: 0.9957\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0102 - accuracy: 0.9967\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0078 - accuracy: 0.9975\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0122 - accuracy: 0.9959\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0105 - accuracy: 0.9964\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0080 - accuracy: 0.9973\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0072 - accuracy: 0.9978\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0084 - accuracy: 0.9974\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0067 - accuracy: 0.9977\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0059 - accuracy: 0.9981\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0073 - accuracy: 0.9975\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0092 - accuracy: 0.9972\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0062 - accuracy: 0.9983\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0068 - accuracy: 0.9981\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 6.2242e-04 - accuracy: 0.9999\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 1.3274e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 5.3871e-05 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 9.0153e-04 - accuracy: 0.9997\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0153 - accuracy: 0.9956\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ba68cba688>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 학습\n",
    "model.fit(X_train, y_tr_en, epochs = 50, batch_size = 256, verbose = 1)\n",
    "\n",
    "# batch_size : 전체데이터 활용시 한꺼번에 넣으면 연산량이 많아져 학습이 힘들다\n",
    "# 단위별로 쪼개서 학습하게 만듦\n",
    "# verbose : 학습현황 출력하라는 뜻(기본값=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43be9895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.45490196,\n",
       "        0.49019608, 0.67058824, 1.        , 1.        , 0.58823529,\n",
       "        0.36470588, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.6627451 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.85490196, 0.11764706,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.6627451 , 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.83529412, 0.55686275, 0.69019608,\n",
       "        0.99215686, 0.99215686, 0.47843137, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20392157, 0.98039216, 0.99215686, 0.82352941, 0.1254902 ,\n",
       "        0.04705882, 0.        , 0.02352941, 0.80784314, 0.99215686,\n",
       "        0.54901961, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30196078, 0.98431373,\n",
       "        0.82352941, 0.09803922, 0.        , 0.        , 0.        ,\n",
       "        0.47843137, 0.97254902, 0.99215686, 0.25490196, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12156863, 0.07058824, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.81960784, 0.99215686,\n",
       "        0.99215686, 0.25490196, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.45882353, 0.96862745, 0.99215686, 0.77647059, 0.03921569,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.29803922, 0.96862745, 0.99215686,\n",
       "        0.90588235, 0.24705882, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.50196078, 0.99215686, 0.99215686, 0.56470588, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.69019608, 0.96470588, 0.99215686,\n",
       "        0.62352941, 0.04705882, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09803922,\n",
       "        0.91764706, 0.99215686, 0.91372549, 0.1372549 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.77647059, 0.99215686, 0.99215686,\n",
       "        0.55294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.30588235,\n",
       "        0.97254902, 0.99215686, 0.74117647, 0.04705882, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0745098 , 0.78431373, 0.99215686, 0.99215686,\n",
       "        0.55294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.5254902 ,\n",
       "        0.99215686, 0.99215686, 0.67843137, 0.04705882, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97254902, 0.99215686, 0.99215686,\n",
       "        0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.97254902, 0.99215686, 0.99215686, 0.16862745, 0.07843137,\n",
       "        0.07843137, 0.07843137, 0.07843137, 0.01960784, 0.        ,\n",
       "        0.01960784, 0.07843137, 0.07843137, 0.14509804, 0.58823529,\n",
       "        0.58823529, 0.58823529, 0.57647059, 0.03921569, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.97254902, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.65882353, 0.56078431, 0.65098039, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.48235294, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.68235294, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.97647059, 0.96862745,\n",
       "        0.96862745, 0.6627451 , 0.45882353, 0.45882353, 0.22352941,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4627451 , 0.48235294, 0.48235294, 0.48235294, 0.65098039,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.60784314, 0.48235294,\n",
       "        0.48235294, 0.16078431, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce337431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [[1.0792298e-16 3.8131628e-15 1.0000000e+00 2.8980602e-14 5.8719878e-26\n",
      "  3.7683778e-23 1.5105610e-19 4.7637815e-17 5.1822918e-17 6.1094925e-25]]\n",
      "예측값: 2\n",
      "실제값: 2\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "pre = model.predict(X_test[1:2])\n",
    "print('예측값:', pre)\n",
    "print('예측값:', pre.argmax()) #최대값이 든 인덱스 번호 반환\n",
    "print('실제값:', y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef945f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7a3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec498d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
